{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESSED_FOLDER = \"data/google_stocks/preprocessed\"\n",
    "\n",
    "df = pd.read_csv(\"data/google_stocks/stock_data.csv\")\n",
    "df_mean = df[[\"Open\", \"Close\", \"High\", 'Low']].mean(axis=1)\n",
    "\n",
    "# Normalize the dataset.\n",
    "def normalize(dataframe:pd.DataFrame):\n",
    "    _min, _max = dataframe.min(), dataframe.max()\n",
    "\n",
    "    return (dataframe - _min)/(_max - _min)\n",
    "\n",
    "df_normalized = normalize(df_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dset:np.ndarray, train_size=0.7):\n",
    "    shape = dset.shape\n",
    "    train_idx = int(shape[0]*train_size)\n",
    "    \n",
    "    dset = dset.reshape((shape[0], 1, shape[-1])).astype(np.float32)\n",
    "    \n",
    "    train = dset[:train_idx]\n",
    "    test = dset[train_idx:]\n",
    "    \n",
    "    return train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dset:np.ndarray):\n",
    "    rng = np.random.default_rng()\n",
    "    window_length = 30\n",
    "    sequences = []\n",
    "    \n",
    "    for i in range(0, dset.shape[0]- window_length):\n",
    "        sequence = dset[i: i+window_length]\n",
    "        sequences.append(sequence)\n",
    "        \n",
    "    return rng.permutation(np.array(sequences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Somme Sequences\n",
    "def plot_several_sequence(dset, count):\n",
    "    for i in range(count):\n",
    "        fig = plt.figure(figsize=(18, 3))\n",
    "        \n",
    "        plt.plot(dset[i][0], '.-')\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the in sample dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style_dataset = make_dataset(df_normalized.values)\n",
    "\n",
    "style_train, style_test= train_test_split(style_dataset)\n",
    "\n",
    "np.save(f\"{PREPROCESSED_FOLDER}/style_train.npy\", style_train)\n",
    "np.save(f\"{PREPROCESSED_FOLDER}/style_test.npy\", style_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the \"In Sample Dataset\"\n",
    "\n",
    "As said in the paper, this content dataset bahave in the same dataset. So, a Simple permutation is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng() # Applying the new numpy Generator.\n",
    "\n",
    "content_train = rng.permutation(style_train)\n",
    "content_test = rng.permutation(style_test)\n",
    "\n",
    "np.save(f\"{PREPROCESSED_FOLDER}/normal_content_train.npy\", content_train)\n",
    "np.save(f\"{PREPROCESSED_FOLDER}/normal_content_test.npy\", content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_several_sequence(content_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the \"perturbed\" Dataset.\n",
    "\n",
    "The \"Perturbed\" Dataset a modification for the content part of the Style Time. \n",
    "\n",
    "\"\"\"\n",
    "For example, one can add a randomly shifted and scaled unit-step function to each example in the training dataset. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_step_function(\n",
    "    x:np.ndarray, \n",
    "    step_time:float, \n",
    "    step_value:float):\n",
    "    \n",
    "    _step = np.zeros_like(x)\n",
    "    _step[step_time:] = step_value\n",
    "    \n",
    "    return x+ _step\n",
    "\n",
    "\n",
    "def make_perturbed_dataset(dset:pd.DataFrame):\n",
    "    rng = np.random.default_rng() # Applying the new numpy Generator.\n",
    "    perturbed_dataset = []\n",
    "\n",
    "    for sequence in dset:\n",
    "        random_time = int(np.random.uniform(0, sequence.shape[0]))\n",
    "        std_value= np.std(sequence)\n",
    "        random_value = np.random.uniform(-std_value, std_value)\n",
    "        \n",
    "        perturbed_dataset.append(make_step_function(sequence, random_time, random_value))\n",
    "    \n",
    "    return rng.permutation(perturbed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_train = make_perturbed_dataset(style_train)\n",
    "perturbed_test = make_perturbed_dataset(style_test)\n",
    "\n",
    "plot_several_sequence(perturbed_train, 5)\n",
    "\n",
    "np.save(f\"{PREPROCESSED_FOLDER}/perturbed_content_train.npy\", perturbed_train)\n",
    "np.save(f\"{PREPROCESSED_FOLDER}/perturbed_content_test.npy\", perturbed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
